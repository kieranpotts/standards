= TS-1: Guiding Principles for Software Development
:toc: macro
:toc-title: Contents

This technical standard offers a framework for approaching software development projects. It outlines key principles for software design and construction that are proven to lead to successful outcomes.

Related technical standards include:

* link:./010-system-design.adoc[TS-10: System Design], which establishes some key principles of software architecture.
* link:./012-application-architecture.adoc[TS-12: Application Architecture], which covers patterns for standalone applications.
* link:./013-code-design.adoc[TS-13: Code Design], which covers low-level concerns such as code formatting and local design patterns.

toc::[]

== Design for change

The ultimate quality of any software system is its ability to be changed.

Every software application is a product that exists to meet a need. The challenge with software is that it's not always clear what those needs are, so the requirements are often vague and incomplete. There's rarely an obvious solution either, with all the options involving different trade-offs. These are the sorts of *wicked problems* that software developers routinely face.

.Wicked problems
****
A wicked problem lacks a clear definition and has no obvious solution. Horst Rittel and Melvin Webber coined the term in their 1973 paper "Dilemmas in a General Theory of Planning". They used this term to describe the complex issues they faced in their work as urban planners. The concept is now used in various fields, including software development.
****

Even for continuously-released software, like web apps, choosing which features to prioritize for the next shipment can be difficult. Rarely is there a shortage of ideas. What is hard is knowing which ones will deliver the most value to users.

https://ai.stanford.edu/~ronnyk/ExPThinkWeek2009Public.pdf[A 2009 Microsoft research paper] found that only one in three product experiments – done using techniques like A/B testing – lead to meaningful improvements in the metrics they were meant to improve. This means two-thirds of product ideas did not deliver the value expected of them. In other companies, with less mature product development practices, the failure rate may be even higher. Studies suggest that up to https://www.split.io/blog/the-80-rule-of-software-development/[80% of features] in software products are rarely or never used.

The data shows that we often can't tell up-front if developing a feature will be worth it. This is true for the development of lots of products, but it seems to be especially true for software products.

Even when requirements are known, they are rarely stable. Software requirements tend to change over time, and sometimes in unpredictable ways. In enterprise application software, requirements often change due to business needs and outside factors like regulations and market conditions. Different stakeholders within a business can have conflicting requirements and different priorities – common issues. In consumer software, lots of product iteration is often necessary before good product-market fit is found.

[quote, Steve Jobs]
____
People don't know what they want until you show it to them.
____

In some cases, we may not even know what problem we're trying to solve with the software we're developing. This is often the case in R&D projects, or when building software for new business models. Such innovative projects are driven by exploration and experimentation. Requirements are discovered, not known.

Of course, some software projects do have known and stable requirements. "Replatforming" projects, in which an old system is fully replaced by a new one, with like-for-like functionality, is an example. But even these projects have some uncertainty. At the very least there's the maintenance costs. All software requires ongoing maintenance: dependencies will need to be updated, newly discovered vulnerabilities patched, and code and configuration may need reworking for compliance with new runtimes and standards, and so on. If software is not maintained, *software rot* sets in. These costs cannot be known in advance.

.Software rot
****
"Software rot" describes how computer programs can decline in performance over time, even if nothing changes. All software relies on other software and hardware, like operating systems and utilities. Those dependencies will themselves change over time. All software must be continually maintained to keep it working properly in the changing computing environment in which it operates.
****

So there are all sorts of reasons why a piece of software may need to change after its initial construction. We may need to add new features, remove unused ones, fix bugs, improve performance, update dependencies, patch vulnerabilities, migrate data, increase capacity… and so on, and so on. Most software systems remain in a perpetual state of continuous development. Unlike most physical products, most software is never truly finished.

A universal truth of _all_ software projects is that *requirements are emergent*. The degree to which requirements emerge varies from project to project, but it is almost always the case that requirements will evolve, to some degree, after construction has started – no matter how hard you try to lock down the requirements at the start.

At least we have an advantage over the development of physical products. We can change software after it is delivered. The clue is in the name. Software is _soft_ – it is malleable and changeable by nature. We can make software do different things by simply changing bits of its code and configuration. Usually, we don't need to redevelop the whole thing. This is not the case with most physical goods.

The natural response to the inherent uncertainty in software projects is to try to lock down requirements early. A better strategy is to leverage software's malleability and design our software to be easily changed. If we can do that, we won't need to wait on everything being perfectly planned before we get started on the construction. We can write the code even while the requirements remain vague and incomplete. As the requirements become clearer with time, we change the code to meet the evolving requirements.

Systems that are easy to change tend to have long useful lives and deliver a high return on investment. Changeability – also known as evolvability – is the ultimate quality of a software system.

Achieving this requires investment in software design. Changeability is a quality that is built-in to the code hierarchies, data structures, and communication patterns of software.

Good software design is not so much about finding the perfect solution to a problem. It is more about having a plan to adapt to changing problems.

== Develop iteratively and incrementally

Designing for change is about more than code and data. It is also about _how_ we make software.

We cannot separate design from process. The methods and tools we use to develop software directly impact its design.

The best way to design software for change is through an *iterative and incremental development* process. The idea is to develop a product through repeated cycles (iterations), building it in small portions (increments). In each cycle, we further develop user-facing functionality while evolving the design to better accommodate the system's new capabilities.

This development model is powerful because it can be driven by *feedback loops*. We can adjust product roadmaps based on early and regular user feedback, and in response to changing business requirements, new technologies, and new insights learned from our own experience of building the software.

There are lots of different types of feedback loops, and the more of them we implement, the better quality feedback we get, improving our decision making.

An iterative and incremental development process also supports experimentation and innovation, which is essential for solving complex and ambiguous problems.

An iterative and incremental development model lets us *embrace change*, not try to fight it off. We can safely assume that the initial requirements will be incomplete, because we have the freedom to continuously respond to changing requirements, remodelling the software during construction as necessary.

An alternative approach to dealing with the inherent unpredictability of software projects is to try to lock down the requirements early. By doing *big design up-front* before construction, you can reduce the odds that changes will be necessary later. Costs and timelines for construction can be estimated with greater confidence, too. At least, that's the theory.

In the IT industry, any development process like this is colloquially known as being "*waterfall*". A waterfall development process sees each phase of the development lifecycle be done in a sequential manner. A single waterfall cycle may see a whole new software product developed from scratch, or (more commonly) a major new feature integrated into an existing product. Within a waterfall cycle there may be smaller cycles of development and testing sandwiched in the middle, but the overall process puts emphasis on getting requirements specifications finalized and comprehensive designs signed-off before construction begins. When construction is done, a complete finished solution is released in one *big bang*.

image::./_/stepwise-with-iterations.drawio.png[alt=Waterfall with inner iterations,width=712,height=522]

Waterfall processes are appealing because they give the impression of enforcing order on chaos, making software development more predictable. But it's an illusion. The reality is that waterfall development processes have proven to be risky and expensive – especially for complex software.

Waterfall processes involve protracted up-front planning phases, which add overhead and extend delivery schedules, increasing costs and delaying time-to-market. Waterfall processes stifle innovation by leaving no room for experimentation, and they encourage *over-engineering* – building features that users don't actually need, and designing complex solutions where simpler ones will do. Because software updates are released in big batches, feedback loops are extended, meaning gaps in requirements and flaws in designs are discovered late, increasing the cost of making changes.

Waterfall processes are popular in organizations with top-down, command-and-control management styles. They are characterized by lots of bureaucracy, rigid stepwise phases, and centralized change management procedures. You often see developers assigned to tasks like estimation and scheduling, diverting their attention from the essential job of delivering useful software to customers. Worse, technicians get taken away from any decision making concerning the software they're responsible for making, seeing their jobs reduced to the production of code. This breaks critical feedback loops, and software design is restricted to solving immediate problems rather than planning for change.

Most fatally of all, waterfall processes discourage requirements from being allowed to change, by fixing budgets and schedules at the start. Inevitably, *scope creeps* as more requirements are discovered after construction has begun. If budgets and schedules are not adjusted in response to changes in scope, then quality suffers. And when quality suffers, changeability is reduced, increasing the cost of future changes.

Fixing costs for software construction is a false economy. It leads to suboptimal solutions that are more expensive to maintain and develop further.

The waterfall development model is fundamentally flawed because it treats software development as a construction process rather than a design process.

Waterfall processes are unsuitable for most software projects. Unless the requirements can be guaranteed to be complete, precise, and stable from the start, waterfall only creates an illusion of project control while undermining flexibility and quality, and masking inefficiencies and hidden costs.

This is why so many software projects go over budget and over schedule, or otherwise fail to meet the needs of the target users. It's rarely for lack of technical expertise. It's because so much software is developed under an ill-suited process.

No matter how much we invest in up-front planning, we will always be wrong about some things. Software development is a wicked problem. Requirements are emergent for all sorts of reasons. Even if we are successful in locking down requirements, there will be lots of nuances in the many trade-offs in the design that we can grasp only by testing working software. (Prototypes can certainly help to make better designs decisions ahead of construction. But to validate requirements and designs there's really nothing better than putting production-grade software in the hands of real users.)

Rather than dealing with uncertainty by trying to eliminate it, we should accept that uncertainty is an intrinsic characteristic of any kind of product design process.

Instead, we should tap into the strength of software's malleability. We should design our software to be easily changed, so we can develop it iteratively and incrementally in collaboration with its users, who constantly evaluate the evolving product and guide its development in the right direction.

Almost all successful software projects are delivered through a process of piecemeal growth driven by fast feedback loops. Iterative and incremental development offers a long-established framework for doing this.

== High-level design up-front

That being said, _some_ amount of up-front design is always useful.

The design work we _do_ want to do up-front is the stuff that is going to be difficult to change later. Changing the programming language in which an application is written is always going to be expensive – there isn't much you can do about that. Changing the patterns of communication between different parts of a distributed system is another example. Anything that involves changing the _fundamental structures_ of code, data, and communication is never going to be easy to change.

This known as the *high-level design* (HLD). The HLD establishes the overall architectural style of an IT solution. It determines the boundaries between modules, the interfaces and communication patterns between modules, the management of state, and the choices of programming languages, database management systems, and other infrastructure.

The high-level design is determined by the problem space in which the software operates. It is perfectly reasonable for us to expect the problem space of a software system to remain consistent for the life span of that system. We should not expect to be able to pivot from developing a windowing system to an operating system shell, for example – not without throwing away everything and starting over. These are entirely different problem spaces, and so the solutions require entirely different architectural styles, different technology stacks, different construction methods, different testing tools, and different deployment and release strategies. They're different products in every way, except for the fact they're both software products.

When we refer to software changeability, we mean the ability to change a software system _within its existing business domain_. Once we've settled on the high-level design for a solution, we should not expect to need to change it significantly.

While the high-level design is not expected to change, the high-level design _is_ required to support changes being made to the parts within it. A requirement of the high-level design is to provide systems – built-in to the software itself – by which the parts of the software can be reconfigured, added, removed, or replaced. Evolutionary design is constrained to lower-level changes within an established high-level design.

// These are all examples of *cross-cutting concerns* that are hard to change later, so we want to get them right early.

// Design is a very nuanced thing, involving lots off trade-offs. We can't always judge those trade-offs up-front. Sometimes we just have to experiment with alternative designs, and test them in real working software.

// Cross-cutting concerns, which are hard to change later, are baked into the HLD.

// In each cycle, we make design changes to accommodate the product's evolving capabilities. *Evolutionary design* happens through continuous refactoring, done in parallel to the addition and subtraction of user-facing features.

// It should be shallow, not deep. Early design should be focused on the high-level design: establishing the overall architecture of the solution, the boundaries between modules, the interfaces and communication patterns between the modules, the management of state, the technology stack, and so on. Early design effort should prioritize the stuff that is going to be hard to change later.

// That said, we should not expect to need to change the *high-level design* of a software system.


//

// TODO: Don't lock down the high-level design too early. *Project paradox* - you know the least at the start of a project, at exactly the time when you need to implement the high-level design. Err on the side of starting with a monolith – but make it as modular as possible – while you iterate on the high-level design. As soon as you start extracted services, you are committing to a high-level design that is hard to change later.

// For all these reasons, the optimum solution tends to emerge quite late in the development process – often a considerable time after construction has begun.

// -------------------------------------------

// == Advantages

// Predictability:
// * Clear project scope and timelines
// * Detailed cost estimates
// * Well-defined deliverables
// * Reduced scope creep

// Risk Management:
// * Early identification of major technical challenges
// * Comprehensive risk analysis before commitment
// * Clear dependencies and integration points

// Large Team Coordination:
// * Detailed specifications enable parallel development
// * Clear interfaces between team responsibilities
// * Reduced communication overhead during implementation

// Regulatory Compliance:
// * Extensive documentation for audit trails
// * Formal approval processes
// * Traceability from requirements to implementation

// This approach can make sense in high-stakes systems (eg. life-critical software such as medical devics and aircraft, and financial trading systems) and in well-understood domains (mature problem spaces with stable requirements; or when replacing existing systems with known functionality; regulated industries with fixed specifications). It is often necessary in outsourced development done under fixed-cost, fixed-term contracts.

// == Disadvantages

// Inflexibility:
// * Difficult and expensive to accommodate changing requirements
// * Late discovery of design flaws
// * Assumptions made early may prove incorrect

// Long Time-to-Market:
// * Extended planning phases delay value delivery
// * No working software until late in the process
// * Difficult to validate assumptions without implementation

// Risk of Over-Engineering:
// * Designing for requirements that may never materialize
// * Complex solutions to simple problems
// * Gold-plating and feature bloat

// Poor Feedback Loops:
// * Users don't see working software until late
// * Integration issues discovered late
// * Performance problems identified after implementation

// == Modern Alternatives

// Agile/Iterative:
// * Short development cycles with frequent delivery
// * Continuous feedback and adaptation
// * Working software over comprehensive documentation

// Lean Startup:
// * Build-Measure-Learn cycles
// * Minimum Viable Product (MVP) approach
// * Validated learning through experimentation

// Design Thinking:
// * User-centered design process
// * Rapid prototyping and testing
// * Iterative refinement based on user feedback

// Modern development often uses "Just Enough" Design:

// * Sufficient up-front planning to avoid major pitfalls
// * Architecture that can evolve with requirements
// * Documentation that enables progress without constraining change
// * Risk-based approach to determine design depth

// Example Balance:

// ----
// High-Level Architecture: Detailed up-front planning
// System Interfaces: Well-defined contracts
// Implementation Details: Iterative refinement
// User Experience: Prototype and test early
// ----

// The optimal amount of up-front design depends on:

// * Problem complexity and novelty
// * Cost of change (higher cost = more up-front design)
// * Team size and distribution
// * Regulatory and compliance requirements
// * Time constraints and market dynamics

// Big up-front design isn't inherently good or bad—it's a tool that works well in certain contexts but can be counterproductive when applied inappropriately to dynamic, uncertain, or innovative projects.

// -------------------------------------------

// Joel Spolsky, a popular online commentator on software development, has argued strongly in favor of big design up-front:[2]

//     "Many times, thinking things out in advance saved us serious development headaches later on. ... [on making a particular specification change] ... Making this change in the spec took an hour or two. If we had made this change in code, it would have added weeks to the schedule. I can’t tell you how strongly I believe in Big Design Up-Front, which the proponents of Extreme Programming consider anathema. I have consistently saved time and made better products by using BDUF and I’m proud to use it, no matter what the XP fanatics claim. They’re just wrong on this point and I can’t be any clearer than that."

// However, several commentators[3][4][5] have argued that what Spolsky has called big design up-front doesn't resemble the BDUF criticized by advocates of XP and other agile software development methodologies because he himself says his example was neither recognizably the full program design nor completed entirely up-front: [6]

//     "This specification is simply a starting point for the design of Aardvark 1.0, not a final blueprint. As we start to build the product, we'll discover a lot of things that won't work exactly as planned. We'll invent new features, we'll change things, we'll refine the wording, etc. We'll try to keep the spec up to date as things change. By no means should you consider this spec to be some kind of holy, cast-in-stone law."

// Critics (notably those who practice agile software development) argue that BDUF is poorly adaptable to changing requirements and that BDUF assumes that designers are able to foresee problem areas without extensive prototyping and at least some investment into implementation. For substantial projects, the requirements from users need refinement in light of initial deliverables, and the needs of the business evolve at a pace faster than large projects are completed in - making the Big Design outdated by the time the system is completed.

// They also assert that there is an overhead to be balanced between the time spent planning and the time that fixing a defect would actually cost. This is sometimes termed analysis paralysis.

== Optimize for learning through fast feedback loops

// TODO: There are lots of different feedback loops (tests, code review, monitoring, logging, etc.) but the ones that matter the most are those from users. Again, there are multiple channels, including social media sites...

Software development is primarily a learning process. First, we need to learn about the business domain and the problem we're trying to solve within it. Then, through an incremental product development process, we iterate the solution by delivering small changes to users as quickly as possible, learning from the feedback that the users provide, and adjusting our plans for subsequent increments in response to that feedback.

We're also continuously learning from our own experience of building the software. For example, what design patterns are proving to be the most effective at supporting change?

It follows that we should optimize our software development process for learning. We do this by building in lots and lots of feedback loops, and keeping those feedback loops as short as possible – so the effect is that feedback is more-or-less continuous.

We can shorten the time it takes to get feedback from users by increasing our release cadence. The objective should be to deliver software updates to users as _continuously_ as possible. This requires investment in methods and tools such as canary and beta release channels, blue-green deployments, A/B testing, and feature flags. Test automation, continuous integration and delivery (CI/CD) pipelines, and comprehensive monitoring also reduce friction, costs, and risks in the process of shipping software updates.

Thus, software that is designed to change is not only easy to modify and extend, but it also has built-in feedback loops. For example, integrated monitoring systems generate usage analytics data, and feature flags allow us to run experiments – try out new ideas quickly and cheaply.

Taken to extremes, fully automated delivery pipelines support continuous deployment, in which mere hours pass between code changes being committed and those changes existing in a production or production-like environment. The faster we can get our code changes into the hands of users, the less likely we are to waste time and money building features that those users don't want or need.

// There are many different types of feedback loops that you can integrate into your software development workflow. The appropriate types of loops will vary depending on the type of software you're making. But you want to have a good mix of quantitative and qualitative feedback.

There should be multiple feedback loops from the product's users to its developers. User feedback should be a mix of manual qualitative analysis (eg. user interviews and usability testing) and automated quantitative analysis (eg. usage analytics and A/B testing). Most user feedback should be driven by questions we want to answer, or hypotheses we want to test. How are users interacting with the software? What are their pain points? What features are they finding most valuable? What features are they not using? What features do they want that we haven't built yet? User feedback can also be open-ended; customer support tickets, user forums, and social media are all good sources of unsolicited user feedback.

User feedback is not the only type of feedback loop. There are many other feedback loops, eac serving different purposes. Code reviews and pair programming provide feedback on code quality (maintainability, changeability). Automated tests provide feedback on the correctness and stability of the software. Monitoring systems and analytics data provide feedback on performance and reliability of the software. Retrospectives and post-mortems provide feedback on the development process itself.

All of these feedback loops allow us to make data-driven decisions about the direction of the software's development, to iterate its design more effectively, and to iterate the design of the workflows that support its development.

Continuous learning through fast feedback is the foundation for building agility into the software development process. To be "agile" in software development means to be able to respond quickly and effectively to change.

[quote, Jeff Bezos]
____
Success can come through iteration: invent, launch, reinvent, relaunch, start
over, rinse, repeat, again and again.
____
