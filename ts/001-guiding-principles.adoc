= TS-1: Guiding Principles for Software Development
:toc: macro
:toc-title: Contents

This technical standard offers a framework for approaching software development projects. It outlines key principles for software design and construction that are proven to lead to successful outcomes.

Related technical standards include:

* link:./010-system-design.adoc[TS-10: System Design], which establishes some key principles of software architecture.
* link:./012-application-architecture.adoc[TS-12: Application Architecture], which covers patterns for standalone applications.
* link:./013-code-design.adoc[TS-13: Code Design], which covers low-level concerns such as code formatting and local design patterns.

toc::[]

== Design for change

The ultimate quality of any software system is its ability to be changed.

Every software application is a product that exists to meet a need. The challenge is that it's not always clear what those needs are, so the requirements are often vague and incomplete. There's rarely an obvious solution either, and all the options involve different trade-offs. These are the sorts of *wicked problems* that software developers routinely face.

.Wicked problems
****
A wicked problem lacks a clear definition and has no obvious solution. Horst Rittel and Melvin Webber coined the term in their 1973 paper "Dilemmas in a General Theory of Planning". They used this term to describe the complex issues they faced in their work as urban planners. The concept is now used in various fields, including software development.
****

Even for continuously-released software, like web apps, choosing which features to prioritize for the next shipment can be difficult. Rarely is there a shortage of ideas. What is hard is knowing which ones will deliver the most value to users.

https://ai.stanford.edu/~ronnyk/ExPThinkWeek2009Public.pdf[A 2009 Microsoft research paper] found that only one in three product experiments – done using techniques like A/B testing – lead to meaningful improvements in the metrics they were meant to improve. This means two-thirds of product ideas did not deliver the value expected of them. In other companies, with less mature product development practices, the failure rate may be even higher. Studies suggest that up to https://www.split.io/blog/the-80-rule-of-software-development/[80% of features] in software products are rarely or never used.

The data shows that we often can't tell up-front if developing a feature will be worth it. This is true for a lot of product development, but it seems to be especially true for software products.

Even when requirements are known, they are rarely stable. Requirements tend to change over time, and sometimes in unpredictable ways. In enterprise application software, requirements often change due to business needs and outside factors such as regulations and market conditions. Different stakeholders within a business can also have conflicting priorities. In consumer software, lots of product iteration is often necessary before a good product-market fit is found.

[quote, Steve Jobs]
____
People don't know what they want until you show it to them.
____

In some cases, we may not even know what problem we are solving with our software. This is often the case in R&D projects or when building software for new business models. These innovative projects are driven by exploration and experimentation. Requirements are discovered, not known.

Some software projects have stable requirements, like platform migrations that replace old systems with like-for-like features. But even these projects face uncertainty. At the very least, the software will need to be maintained: dependencies updated, newly discovered vulnerabilities patched, code and configuration refactored for compliance with new runtimes and standards, and so on. These costs cannot be predicted accurately. They cannot be ignored either. If software is not maintained, *software rot* sets in.

.Software rot
****
"Software rot" describes how computer programs can decline in performance over time, even if nothing changes. All software relies on other software and hardware, like operating systems and utilities. Those dependencies will themselves change over time. All software must be continually maintained to keep it working properly in the changing computing environment in which it operates.
****

There are all sorts of reasons why a piece of software may need to change after its initial construction. We may need to add new features, remove unused ones, fix bugs, improve performance, update dependencies, patch vulnerabilities, migrate data, increase capacity… and so on, and so on. Most software systems remain in a perpetual state of continuous development. Unlike most physical products, most software is never truly finished.

A universal truth of _all_ software projects is that *requirements are emergent*. Requirements are rarely understood in full at the start of a project, and they will keep evolving long after construction has begun.

At least we have an advantage over the development of physical products: we can change software after it is delivered. The clue is in the name. Software is _soft_ – it is malleable and changeable by nature. We can make software do different things just by changing bits of its code and configuration. Usually, we don't need to rebuild the whole thing. This isn’t the case with most physical goods.

The natural response to the inherent uncertainty in software projects is to try to lock down requirements early. A better strategy is to *embrace change*. Instead of planning every feature in detail, we should assume that requirements will be vague, incomplete, or even plain wrong. But the requirements will become clearer with time, as we learn more about the problem space, and the trade-offs in the solution. When the requirements change, we change the software to meet the new requirements.

Systems that are easy to change tend to have long useful lives and deliver a high return on investment.

Changeability, also known as evolvability, is the ultimate quality of a software system.

Achieving changeability requires an investment in the software's design. Changeability is an attribute of the code hierarchy, the data structures, and the communication patterns.

Good software design solves the problem _and_ plans for the problem to change.

== Develop iteratively and incrementally

Designing for change is about more than code and data. It is also about how we make software.

We cannot separate design from process. The methods and tools we use to develop software directly impact its design. The design of software is a consequence of the process under which it was made.

[quote, Melvin Conway, 1967 (Conway's Law)]
____
Organizations which design systems… are constrained to produce designs which are copies of the communication structures of these organizations.
____

The best way to design software for change is through an *iterative and incremental development* process. The idea is to develop a product through repeated cycles (iterations), building it in small portions (increments). In each cycle, we further develop user-facing functionality while evolving the design to better accommodate the system's new capabilities.

This development model is powerful because it can be driven by *feedback loops*. We can adjust product roadmaps based on early and regular user feedback, and in response to changing business requirements, new technologies, and new insights learned from our own experience of building the software.

An iterative and incremental development process also supports experimentation and innovation, which is essential for solving complex and ambiguous problems.

An iterative and incremental development model helps us to continuously refine product requirements and improve the design over time. We can implement lots of feedback loops through which we continuously learn more about the problem space we're working in, and the trade-offs involved in our solution to it, and adjust our plans in response.

Almost all successful software projects are delivered through a process of piecemeal growth driven by fast feedback loops. Iterative and incremental development offers a long-established framework for doing this.

An alternative approach to dealing with the inherent unpredictability of software projects is to try to lock down the requirements and designs early. By doing *big design up-front* before construction, followed by *big bang* releases after construction, the idea is to remove uncertainty by reducing the chances of any changes being necessary. With such detailed up-front planning, costs and timelines for construction and testing can be estimated with greater confidence.

In the IT industry, any development process like this is colloquially referred to as being "waterfall". A waterfall development process sees each phase of the development lifecycle – discovery and analysis of the problem, requirements specifications, construction, testing, and release – be done in a sequential manner. A single waterfall cycle may see a whole new software product developed from scratch, or a major new feature integrated into an existing product. Within a waterfall cycle there may be smaller cycles of development and testing, but the overall process emphasizes finalizing detailed requirements specifications, and completing comprehensive designs, before construction begins, and delivering a complete finished product in one big release at the end.

Waterfall processes leave the impression of enforcing order on chaos, making software development more predictable. But it's an illusion. Waterfall gives a false sense of certainty. The reality is that, in the construction of complex software, waterfall development processes have been proven to be riskier and more expensive than iterative and incremental development processes.

Protracted up-front planning and design adds overhead and extends delivery schedules. This delays time-to-market, losing commercial advantage. It also encourages *over-engineering* – building features that users don't actually need, and designing complex solutions where simpler ones will do. Waterfall processes stifle innovation by leaving no room for experimentation. And, because software updates are released in big batches, feedback loops are extended, meaning gaps in requirements and flaws in designs are discovered late, increasing the cost of making changes.

Waterfall processes are characterized by centralized change management procedures, rigid stepwise phases, and lots of bureaucracy. A top-down management style often sees technical staff assigned to tasks like estimation and scheduling, diverting their attention from the essential job of delivering useful software to customers.

// TODO: Add stepwise diagram from the waterfall paper.

Most fatally of all, waterfall processes discourage product requirements from being allowed to change, because budgets and schedules are fixed at the outset. If scope is allowed to creep without flexing budgets and schedules, then quality suffers – reducing the software's changeability, and so increasing the cost of future changes.

This is why so many software projects go over budget and over schedule, or otherwise fail to meet the needs of the target users. It's rarely for lack of technical expertise. It's because so much software is developed under an ill-suited process.

Unless the requirements can be guaranteed to be complete, precise, and stable, waterfall will give you false guarantees on costs and timelines.

Rarely can you guarantee that requirements will be complete, precise, and stable. No matter how much we invest in planning, we will always be wrong about some things. Software development is a wicked problem. Requirements are emergent for all sorts of reasons. Even if we are successful in locking down requirements, there will be lots of nuances in the many trade-offs in the design that we can grasp only by testing working software. Prototypes can certainly help to make better decisions up-front, but there's nothing quite like real production-grade software, put in the hands of real users, to validate requirements and designs.

Rather than dealing with uncertainty by trying to eliminate it, we should accept that uncertainty is an intrinsic characteristic of any kind of product design process.

Instead, we should tap into the strength of software's malleability. We should design our software to be easily changed, so we can develop it iteratively and incrementally in collaboration with its users, who constantly evaluate the evolving product and guide its development in the right direction.

== High-level design up-front, low-level design just-in-time

That being said, _some_ amount of up-front design is always useful.

// Cross-cutting concerns, which are hard to change later, are baked into the HLD.

// In each cycle, we make design changes to accommodate the product's evolving capabilities. *Evolutionary design* happens through continuous refactoring, done in parallel to the addition and subtraction of user-facing features.

// It should be shallow, not deep. Early design should be focused on the high-level design: establishing the overall architecture of the solution, the boundaries between modules, the interfaces and communication patterns between the modules, the management of state, the technology stack, and so on. Early design effort should prioritize the stuff that is going to be hard to change later.

// That said, we should not expect to need to change the *high-level design* of a software system. The high-level design will always be hard to change, because this is about the fundamental organization of the logic, the structure of the data, and even the very choices of programming languages, databases, and other technology and supporting infrastructure.

// The high-level design is determined by the problem space in which the software operates. It is perfectly reasonable for us to expect the problem space of a software system to remain consistent for the life span of that system. We should not expect to be able to pivot from developing a windowing system to an operating system shell, for example – not without throwing away everything and starting over. These are entirely different problem spaces, and so the solutions require entirely different architectural styles, different technology stacks, different construction methods, different testing tools, and different deployment and release strategies. They're different products in every way, except for the fact they're both software products.

// While the high-level design is not expected to change, the high-level design _is_ required to support changes being made to the parts within it. A requirement of the high-level design is to provide systems – built-in to the software itself – by which the parts of the software can be reconfigured, added, removed, or replaced.

// TODO: Don't lock down the high-level design too early. *Project paradox* - you know the least at the start of a project, at exactly the time when you need to implement the high-level design. Err on the side of starting with a monolith – but make it as modular as possible – while you iterate on the high-level design. As soon as you start extracted services, you are committing to a high-level design that is hard to change later.

// For all these reasons, the optimum solution tends to emerge quite late in the development process – often a considerable time after construction has begun.

// -------------------------------------------

// == Advantages

// Predictability:
// * Clear project scope and timelines
// * Detailed cost estimates
// * Well-defined deliverables
// * Reduced scope creep

// Risk Management:
// * Early identification of major technical challenges
// * Comprehensive risk analysis before commitment
// * Clear dependencies and integration points

// Large Team Coordination:
// * Detailed specifications enable parallel development
// * Clear interfaces between team responsibilities
// * Reduced communication overhead during implementation

// Regulatory Compliance:
// * Extensive documentation for audit trails
// * Formal approval processes
// * Traceability from requirements to implementation

// This approach can make sense in high-stakes systems (eg. life-critical software such as medical devics and aircraft, and financial trading systems) and in well-understood domains (mature problem spaces with stable requirements; or when replacing existing systems with known functionality; regulated industries with fixed specifications). It is often necessary in outsourced development done under fixed-cost, fixed-term contracts.

// == Disadvantages

// Inflexibility:
// * Difficult and expensive to accommodate changing requirements
// * Late discovery of design flaws
// * Assumptions made early may prove incorrect

// Long Time-to-Market:
// * Extended planning phases delay value delivery
// * No working software until late in the process
// * Difficult to validate assumptions without implementation

// Risk of Over-Engineering:
// * Designing for requirements that may never materialize
// * Complex solutions to simple problems
// * Gold-plating and feature bloat

// Poor Feedback Loops:
// * Users don't see working software until late
// * Integration issues discovered late
// * Performance problems identified after implementation

// == Modern Alternatives

// Agile/Iterative:
// * Short development cycles with frequent delivery
// * Continuous feedback and adaptation
// * Working software over comprehensive documentation

// Lean Startup:
// * Build-Measure-Learn cycles
// * Minimum Viable Product (MVP) approach
// * Validated learning through experimentation

// Design Thinking:
// * User-centered design process
// * Rapid prototyping and testing
// * Iterative refinement based on user feedback

// Modern development often uses "Just Enough" Design:

// * Sufficient up-front planning to avoid major pitfalls
// * Architecture that can evolve with requirements
// * Documentation that enables progress without constraining change
// * Risk-based approach to determine design depth

// Example Balance:

// ----
// High-Level Architecture: Detailed up-front planning
// System Interfaces: Well-defined contracts
// Implementation Details: Iterative refinement
// User Experience: Prototype and test early
// ----

// The optimal amount of up-front design depends on:

// * Problem complexity and novelty
// * Cost of change (higher cost = more up-front design)
// * Team size and distribution
// * Regulatory and compliance requirements
// * Time constraints and market dynamics

// Big up-front design isn't inherently good or bad—it's a tool that works well in certain contexts but can be counterproductive when applied inappropriately to dynamic, uncertain, or innovative projects.

// -------------------------------------------

// Joel Spolsky, a popular online commentator on software development, has argued strongly in favor of big design up-front:[2]

//     "Many times, thinking things out in advance saved us serious development headaches later on. ... [on making a particular specification change] ... Making this change in the spec took an hour or two. If we had made this change in code, it would have added weeks to the schedule. I can’t tell you how strongly I believe in Big Design Up-Front, which the proponents of Extreme Programming consider anathema. I have consistently saved time and made better products by using BDUF and I’m proud to use it, no matter what the XP fanatics claim. They’re just wrong on this point and I can’t be any clearer than that."

// However, several commentators[3][4][5] have argued that what Spolsky has called big design up-front doesn't resemble the BDUF criticized by advocates of XP and other agile software development methodologies because he himself says his example was neither recognizably the full program design nor completed entirely up-front: [6]

//     "This specification is simply a starting point for the design of Aardvark 1.0, not a final blueprint. As we start to build the product, we'll discover a lot of things that won't work exactly as planned. We'll invent new features, we'll change things, we'll refine the wording, etc. We'll try to keep the spec up to date as things change. By no means should you consider this spec to be some kind of holy, cast-in-stone law."

// Critics (notably those who practice agile software development) argue that BDUF is poorly adaptable to changing requirements and that BDUF assumes that designers are able to foresee problem areas without extensive prototyping and at least some investment into implementation. For substantial projects, the requirements from users need refinement in light of initial deliverables, and the needs of the business evolve at a pace faster than large projects are completed in - making the Big Design outdated by the time the system is completed.

// They also assert that there is an overhead to be balanced between the time spent planning and the time that fixing a defect would actually cost. This is sometimes termed analysis paralysis.

== Optimize for learning through fast feedback loops

Software development is primarily a learning process. First, we need to learn about the business domain and the problem we're trying to solve within it. Then, through an incremental product development process, we iterate the solution by delivering small changes to users as quickly as possible, learning from the feedback that the users provide, and adjusting our plans for subsequent increments in response to that feedback.

We're also continuously learning from our own experience of building the software. For example, what design patterns are proving to be the most effective at supporting change?

It follows that we should optimize our software development process for learning. We do this by building in lots and lots of feedback loops, and keeping those feedback loops as short as possible – so the effect is that feedback is more-or-less continuous.

We can shorten the time it takes to get feedback from users by increasing our release cadence. The objective should be to deliver software updates to users as _continuously_ as possible. This requires investment in methods and tools such as canary and beta release channels, blue-green deployments, A/B testing, and feature flags. Test automation, continuous integration and delivery (CI/CD) pipelines, and comprehensive monitoring also reduce friction, costs, and risks in the process of shipping software updates.

Thus, software that is designed to change is not only easy to modify and extend, but it also has built-in feedback loops. For example, integrated monitoring systems generate usage analytics data, and feature flags allow us to run experiments – try out new ideas quickly and cheaply.

Taken to extremes, fully automated delivery pipelines support continuous deployment, in which mere hours pass between code changes being committed and those changes existing in a production or production-like environment. The faster we can get our code changes into the hands of users, the less likely we are to waste time and money building features that those users don't want or need.

// There are many different types of feedback loops that you can integrate into your software development workflow. The appropriate types of loops will vary depending on the type of software you're making. But you want to have a good mix of quantitative and qualitative feedback.

There should be multiple feedback loops from the product's users to its developers. User feedback should be a mix of manual qualitative analysis (eg. user interviews and usability testing) and automated quantitative analysis (eg. usage analytics and A/B testing). Most user feedback should be driven by questions we want to answer, or hypotheses we want to test. How are users interacting with the software? What are their pain points? What features are they finding most valuable? What features are they not using? What features do they want that we haven't built yet? User feedback can also be open-ended; customer support tickets, user forums, and social media are all good sources of unsolicited user feedback.

User feedback is not the only type of feedback loop. There are many other feedback loops, eac serving different purposes. Code reviews and pair programming provide feedback on code quality (maintainability, changeability). Automated tests provide feedback on the correctness and stability of the software. Monitoring systems and analytics data provide feedback on performance and reliability of the software. Retrospectives and post-mortems provide feedback on the development process itself.

All of these feedback loops allow us to make data-driven decisions about the direction of the software's development, to iterate its design more effectively, and to iterate the design of the workflows that support its development.

Continuous learning through fast feedback is the foundation for building agility into the software development process. To be "agile" in software development means to be able to respond quickly and effectively to change.

[quote, Jeff Bezos]
____
Success can come through iteration: invent, launch, reinvent, relaunch, start
over, rinse, repeat, again and again.
____
