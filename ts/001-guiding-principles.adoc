= TS-1: Guiding Principles of Software Development
:toc: macro
:toc-title: Contents

This technical standard establishes some general guiding principles for the design and implementation of software systems. The intention is not to prescribe concrete rules, but rather to provide a framework for _thinking_ about software design.

Related technical standards include link:./010-system-design.adoc[TS-10: System Design], which describes general software architectural design best practices and standards; link:./012-application-architecture.adoc[TS-12: Application Architecture], which covers architectural patterns for standalone applications; and link:./013-code-design.adoc[TS-13: Code Design], which covers concerns such as code formatting and low-level design patterns.

toc::[]

== Design for change

The ultimate quality of any software system is its ability to be changed.

Every software application is a product that exists to meet a need or want. The challenge is that software development often deals with *wicked problems*. Commonly, requirements are not well defined at the start, because users' needs and wants are unclear. And all the possible solutions make trade-offs.

.Wicked problems
****
A wicked problem lacks a clear definition and has no obvious solution. Horst Rittel and Melvin Webber coined the term “wicked problem” in 1973 in their paper "Dilemmas in a General Theory of Planning". They were urban planners who faced complex issues in their work. This concept is now used in various fields, including software development.
****

Even for continuously-released software, like web apps, choosing which features to prioritize for the next shipment can be difficult. Rarely is there a shortage of ideas. What is hard is knowing which ones will deliver the most value to users.

https://ai.stanford.edu/~ronnyk/ExPThinkWeek2009Public.pdf[A 2009 Microsoft research paper] found that only one in three product experiments – done using techniques like A/B testing – lead to meaningful improvements in the metrics they were meant to improve. This means two-thirds of product ideas did not deliver the value expected of them. In other companies with less mature product development practices, the failure rate may be even higher. Studies suggest that up to https://www.split.io/blog/the-80-rule-of-software-development/[80% of features] in software products are rarely or never used.

The data shows that we often can't tell upfront if developing a feature will be worth it. This is true for all product development, but it seems to be especially for software products.

In enterprise application software, requirements often changes. This is due to business needs and outside factors, such as regulations and market conditions. Different stakeholders within a business may also have conflicting priorities. In consumer software, rapid iteration is often necessary to find a good product-market fit.

[quote, Steve Jobs]
____
People don't know what they want until you show it to them.
____

In some cases, we may not even know what problem we are solving with our software. This is often the case in R&D projects or when building software for new business models. These innovative projects are driven by exploration and experimentation. Requirements are discovered, not known.

Some software projects have stable requirements, like platform migrations that replace old systems with like-for-like features. However, even these projects face uncertainty. At the very least, the software will need to be maintained – dependencies updated, newly discovered vulnerabilities patched, code and configuration refactored for compliance with new runtimes and standards – else *software rot* will set in. The long-term cost of software maintenance is unknown.

.Software rot
****
"Software rot" describes how computer programs can decline in performance over time, even if nothing changes. All software relies on other software and hardware, like operating systems and utilities. Those dependencies will themselves change over time. Therefore, all software must be continually maintained to keep it working properly.
****

There are all sorts of reasons why a piece of software may need to change after its initial construction. We may need to add new features, remove unused ones, fix bugs, improve performance, update dependencies, patch vulnerabilities, migrate data, increase capacity… and so on, and so on. Most software systems remain in a perpetual state of continuous development. Unlike most physical products, most software is never truly finished.

A universal truth of _all_ software projects is that *requirements are emergent*. Requirements are rarely understood in full at the start of a project. They will keep evolving long after construction has begun. This is why early estimates of costs and timelines often prove to have high margins of error.

At least we have an advantage over the development of physical products: we can change software after delivery. The clue is in the name. Software is _soft_, malleable, and changeable. We can make software do different things just by changing bits of its code and configuration. Usually, we don't need to rebuild the whole thing. This isn’t the case with most physical goods.

The natural response to the inherent uncertainty in software projects is to try to lock down requirements early. A better strategy is to *embrace change*. Instead of planning every feature in detail, we should assume that requirements will be vague, incomplete, or even plain wrong. The requirements will become clearer with time, as we learn more about the problem space, and the trade-offs in the solution.

Changeability, also known as evolvability, is the ultimate quality of a software system. Systems that are easy to change tend to have long useful lives and deliver a high return on investment.

Achieving changeability requires investment. It requires deliberate design. Changeability is an attribute of the code's design, the data structures, and the communication patterns.

Good software design solves the problem _and_ it plans for change.

== Develop iteratively and incrementally

Designing for change is not just about the structure of code, data, and communication. It is also about the software development process itself.

We cannot decouple design from process. The methods and tools we use to develop software inevitably have direct impacts on the eventual design of the software. Or, to put it another way, the design of software is a consequence of the process under which it was made.

[quote, Melvin Conway, 1967 (Conway's Law)]
____
Organizations which design systems… are constrained to produce designs which are copies of the communication structures of these organizations.
____

The best way to design software for change is to follow an *iterative and incremental development* process.

This refers to any workflow that supports iterative design within an incremental build model. The general idea is to develop a product through repeated cycles (iterations), building up the product in small portions at a time (increments). In each iteration, design modifications are made to accommodate the product's changing functional and operational capabilities. Thus *evolutionary design* is achieved through continuous refactoring, which happens in parallel to the addition and subtraction of user-facing features.

The iterative and incremental development model is powerful because product development can be driven by *feedback loops*. Product roadmaps can be adjusted early and often in response to user feedback, changing business environments and economic conditions, and new technologies and opportunities. An iterative and incremental development process can also be designed to accommodate experimentation and innovation – which will be required to deliver successful software solutions for some problem domains.

Successful software projects are almost always delivered through a process of *piecemeal growth* driven by fast feedback loops. This requires changeability to be an inherent characteristic of the software development process itself. The ways of working embrace change.

The alternative approach, *big design up-front* before construction, followed by *big bang* releases after construction, is inherently risky and orders-of-magnitude more expensive.

The term *waterfall* is colloquially understood in our industry to refer to any software development model in which emphasis is placed on producing detailed requirements specifications and comprehensive solution designs before construction of a new software product, or a major new feature of an existing software product, begins. Such development methodologies tend to be characterized also by centralized and bureaucratic change management procedures, inflexible stepwise approaches to the phases of the software development lifecycle, and reallocation of technical staff to extraneous tasks such as estimation and scheduling – work that does not contribute to delivering real value to real users.

// TODO: In response to the inherent unpredictability of software development, the waterfall solution is to try to create an illusion of predictability. Artifacts such as story points, kanban boards, and burn-down charts are all attempts to create a semblance of order and predictability in an inherently unpredictable process. These artifacts can be useful, but they can also create a false sense of certainty.

Big up-front planning and design is a perfectly human response to the requirement to manage costs and reduce risks in any kind of construction project. The natural response to uncertainty is to try to remove the uncertainty, by locking down requirements and designs early, and by fixing budgets against estimated costs for construction.

But in the construction of software – at least in the construction of software with non-trivial levels of inherent complexity – this approach has been proven to be costly and fraught with all kinds of risks.

Protracted up-front planning and design adds overhead and extends delivery schedules. This delays time-to-market, losing commercial advantage. Such a process also encourages *over-engineering*, building features that users don't actually want or need, and implementing more complex solutions than a problem requires. Waterfall-like development processes also discourage innovation and experimentation, and they discourage requirements being allowed to change later.

A consequence of waterfall delivery models is that software updates are released to users in big batches. Feedback loops are therefore long and poor quality. This means we don't get to validate all the assumptions we've made in our product plans until late in a project. Gaps in requirements specifications and flaws in designs – such as integration or performance issues – may trigger more substantial rework than would have been necessary had those shortcomings been discovered earlier.

No matter how much time and effort we put into up-front requirements specification, solution design, and delivery planning, we _will_ still be wrong about some things. For the reasons explained in the "Design for change" section above, requirements are emergent for all sorts of reasons, but not least because you don't really know for sure what software features users will find valuable until the users get to actually experience those features first-hand. Accurate cost-benefit analysis of proposed requirements is often not possible until _after_ the necessary changes have been developed and shipped.

Even if we were successful in locking down the requirements specification, the chances are there will be a lot of nuances in the many trade-offs that we will need to make in the software design, and we will only fully understand those trade-offs by running and testing working software. (Prototypes and proofs-of-concept can certainly help to surface some of the more nuanced trade-offs, but there's nothing quite like real production-grade software to validate your designs.)

Big up-front planning and design creates a false sense of certainty. In fact, project risks are more likely to increase than decrease.

So, rather than dealing with uncertainty by trying to eliminate it, we should accept that uncertainty is an intrinsic characteristic of any kind of product design process, and instead design the software – and the process used to make it – to allow for our plans and designs to change.

An iterative and incremental development model allows us to continuously refine product requirements and evolve the solution design as we learn – through lots of continuous feedback loops – more about the problem space we're working in and the trade-offs involved in our solution to it.

== High-level design up-front, low-level design just-in-time

That being said, _some_ amount of up-front design is always useful.

// It should be shallow, not deep. Early design should be focused on the high-level design: establishing the overall architecture of the solution, the boundaries between modules, the interfaces and communication patterns between the modules, the management of state, the technology stack, and so on. Early design effort should prioritize the stuff that is going to be hard to change later.

// That said, we should not expect to need to change the *high-level design* of a software system. The high-level design will always be hard to change, because this is about the fundamental organization of the logic, the structure of the data, and even the very choices of programming languages, databases, and other technology and supporting infrastructure.

// The high-level design is determined by the problem space in which the software operates. It is perfectly reasonable for us to expect the problem space of a software system to remain consistent for the life span of that system. We should not expect to be able to pivot from developing a windowing system to an operating system shell, for example – not without throwing away everything and starting over. These are entirely different problem spaces, and so the solutions require entirely different architectural styles, different technology stacks, different construction methods, different testing tools, and different deployment and release strategies. They're different products in every way, except for the fact they're both software products.

// While the high-level design is not expected to change, the high-level design _is_ required to support changes being made to the parts within it. A requirement of the high-level design is to provide systems – built-in to the software itself – by which the parts of the software can be reconfigured, added, removed, or replaced.

// TODO: Don't lock down the high-level design too early. *Project paradox* - you know the least at the start of a project, at exactly the time when you need to implement the high-level design. Err on the side of starting with a monolith – but make it as modular as possible – while you iterate on the high-level design. As soon as you start extracted services, you are committing to a high-level design that is hard to change later.

// For all these reasons, the optimum solution tends to emerge quite late in the development process – often a considerable time after construction has begun.

// -------------------------------------------

// == Advantages

// Predictability:
// * Clear project scope and timelines
// * Detailed cost estimates
// * Well-defined deliverables
// * Reduced scope creep

// Risk Management:
// * Early identification of major technical challenges
// * Comprehensive risk analysis before commitment
// * Clear dependencies and integration points

// Large Team Coordination:
// * Detailed specifications enable parallel development
// * Clear interfaces between team responsibilities
// * Reduced communication overhead during implementation

// Regulatory Compliance:
// * Extensive documentation for audit trails
// * Formal approval processes
// * Traceability from requirements to implementation

// This approach can make sense in high-stakes systems (eg. life-critical software such as medical devics and aircraft, and financial trading systems) and in well-understood domains (mature problem spaces with stable requirements; or when replacing existing systems with known functionality; regulated industries with fixed specifications). It is often necessary in outsourced development done under fixed-cost, fixed-term contracts.

// == Disadvantages

// Inflexibility:
// * Difficult and expensive to accommodate changing requirements
// * Late discovery of design flaws
// * Assumptions made early may prove incorrect

// Long Time-to-Market:
// * Extended planning phases delay value delivery
// * No working software until late in the process
// * Difficult to validate assumptions without implementation

// Risk of Over-Engineering:
// * Designing for requirements that may never materialize
// * Complex solutions to simple problems
// * Gold-plating and feature bloat

// Poor Feedback Loops:
// * Users don't see working software until late
// * Integration issues discovered late
// * Performance problems identified after implementation

// == Modern Alternatives

// Agile/Iterative:
// * Short development cycles with frequent delivery
// * Continuous feedback and adaptation
// * Working software over comprehensive documentation

// Lean Startup:
// * Build-Measure-Learn cycles
// * Minimum Viable Product (MVP) approach
// * Validated learning through experimentation

// Design Thinking:
// * User-centered design process
// * Rapid prototyping and testing
// * Iterative refinement based on user feedback

// Modern development often uses "Just Enough" Design:

// * Sufficient upfront planning to avoid major pitfalls
// * Architecture that can evolve with requirements
// * Documentation that enables progress without constraining change
// * Risk-based approach to determine design depth

// Example Balance:

// ----
// High-Level Architecture: Detailed upfront planning
// System Interfaces: Well-defined contracts
// Implementation Details: Iterative refinement
// User Experience: Prototype and test early
// ----

// The optimal amount of upfront design depends on:

// * Problem complexity and novelty
// * Cost of change (higher cost = more upfront design)
// * Team size and distribution
// * Regulatory and compliance requirements
// * Time constraints and market dynamics

// Big up-front design isn't inherently good or bad—it's a tool that works well in certain contexts but can be counterproductive when applied inappropriately to dynamic, uncertain, or innovative projects.

// -------------------------------------------

// Joel Spolsky, a popular online commentator on software development, has argued strongly in favor of big design up front:[2]

//     "Many times, thinking things out in advance saved us serious development headaches later on. ... [on making a particular specification change] ... Making this change in the spec took an hour or two. If we had made this change in code, it would have added weeks to the schedule. I can’t tell you how strongly I believe in Big Design Up Front, which the proponents of Extreme Programming consider anathema. I have consistently saved time and made better products by using BDUF and I’m proud to use it, no matter what the XP fanatics claim. They’re just wrong on this point and I can’t be any clearer than that."

// However, several commentators[3][4][5] have argued that what Spolsky has called big design up front doesn't resemble the BDUF criticized by advocates of XP and other agile software development methodologies because he himself says his example was neither recognizably the full program design nor completed entirely upfront: [6]

//     "This specification is simply a starting point for the design of Aardvark 1.0, not a final blueprint. As we start to build the product, we'll discover a lot of things that won't work exactly as planned. We'll invent new features, we'll change things, we'll refine the wording, etc. We'll try to keep the spec up to date as things change. By no means should you consider this spec to be some kind of holy, cast-in-stone law."

// Critics (notably those who practice agile software development) argue that BDUF is poorly adaptable to changing requirements and that BDUF assumes that designers are able to foresee problem areas without extensive prototyping and at least some investment into implementation. For substantial projects, the requirements from users need refinement in light of initial deliverables, and the needs of the business evolve at a pace faster than large projects are completed in - making the Big Design outdated by the time the system is completed.

// They also assert that there is an overhead to be balanced between the time spent planning and the time that fixing a defect would actually cost. This is sometimes termed analysis paralysis.

== Optimize for learning through fast feedback loops

Software development is primarily a learning process. First, we need to learn about the business domain and the problem we're trying to solve within it. Then, through an incremental product development process, we iterate the solution by delivering small changes to users as quickly as possible, learning from the feedback that the users provide, and adjusting our plans for subsequent increments in response to that feedback.

We're also continuously learning from our own experience of building the software. For example, what design patterns are proving to be the most effective at supporting change?

It follows that we should optimize our software development process for learning. We do this by building in lots and lots of feedback loops, and keeping those feedback loops as short as possible – so the effect is that feedback is more-or-less continuous.

We can shorten the time it takes to get feedback from users by increasing our release cadence. The objective should be to deliver software updates to users as _continuously_ as possible. This requires investment in methods and tools such as canary and beta release channels, blue-green deployments, A/B testing, and feature flags. Test automation, continuous integration and delivery (CI/CD) pipelines, and comprehensive monitoring also reduce friction, costs, and risks in the process of shipping software updates.

Thus, software that is designed to change is not only easy to modify and extend, but it also has built-in feedback loops. For example, integrated monitoring systems generate usage analytics data, and feature flags allow us to run experiments – try out new ideas quickly and cheaply.

Taken to extremes, fully automated delivery pipelines support continuous deployment, in which mere hours pass between code changes being committed and those changes existing in a production or production-like environment. The faster we can get our code changes into the hands of users, the less likely we are to waste time and money building features that those users don't want or need.

// There are many different types of feedback loops that you can integrate into your software development workflow. The appropriate types of loops will vary depending on the type of software you're making. But you want to have a good mix of quantitative and qualitative feedback.

There should be multiple feedback loops from the product's users to its developers. User feedback should be a mix of manual qualitative analysis (eg. user interviews and usability testing) and automated quantitative analysis (eg. usage analytics and A/B testing). Most user feedback should be driven by questions we want to answer, or hypotheses we want to test. How are users interacting with the software? What are their pain points? What features are they finding most valuable? What features are they not using? What features do they want that we haven't built yet? User feedback can also be open-ended; customer support tickets, user forums, and social media are all good sources of unsolicited user feedback.

User feedback is not the only type of feedback loop. There are many other feedback loops, eac serving different purposes. Code reviews and pair programming provide feedback on code quality (maintainability, changeability). Automated tests provide feedback on the correctness and stability of the software. Monitoring systems and analytics data provide feedback on performance and reliability of the software. Retrospectives and post-mortems provide feedback on the development process itself.

All of these feedback loops allow us to make data-driven decisions about the direction of the software's development, to iterate its design more effectively, and to iterate the design of the workflows that support its development.

Continuous learning through fast feedback is the foundation for building agility into the software development process. To be "agile" in software development means to be able to respond quickly and effectively to change.

[quote, Jeff Bezos]
____
Success can come through iteration: invent, launch, reinvent, relaunch, start
over, rinse, repeat, again and again.
____
