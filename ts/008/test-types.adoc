= Test types

This section defines the main types of software testing, their use cases, and implementation best practices.

Effective software quality assurance requires selecting and implementing appropriate testing types, which will vary by domain and development lifecycle stage. Organizations should establish testing strategies that combine multiple types of tests, to cover all the scenarios that are relevant to the development goals.

== Static analysis

Most types of tests are dynamic, which means they require the system-under-test to be compiled and executed, so the tests can make assertions on the expected dynamic behaviors of the system.

Static analysis examines the state of the code without executing it. It is possible to identify many categories of potential defects, security vulnerabilities, code quality issues, and standards compliance violations by analyzing the static structure of the source code.

Static analysis tests are easy to automate, and the automated tests are cheap and fast to run because they do not require build steps or isolated test runtime environments. For these reasons, static analysis tests are often deeply integrated into the development process, commonly run automatically when code changes are committed, check in, and/or integrated.

RECOMMENDED strategies:

* Run static analysis checks on revisions (commits), check-ins (pushes to shared repositories), and integrations (before and after merges into trunks).

* Block integrations until all static analysis checks pass.

* Establish clear coding conventions and configure static analysis tools to enforce them consistently.

* Track static analysis metrics over time to measure code quality improvements.

* Use a variety of static analysis tools that specialize in different things such as coding conventions, security, and dependency analysis.

== Behavioral testing (aka. black-box testing)

// Explains the process of giving the input to the system and checking the output, without considering how the system generates the output.

== White-box testing

// The process of giving the input to the system and checking how the system processes the input to generate the output. It is mandatory for a tester to have knowledge of the source code.

// Path coverage: Each and every path within the code is executed at least once to get full path coverage. This is one of the important parts of white box testing.

== Regression testing

// One of the more important types of testing, regression testing checks whether a small change in any component of the application affects the unchanged components or not. This is done by re-executing the previous versions of the application and comparing them to the current version.

== Mutation testing

// The application is tested for the code that was modified after fixing a particular bug or defect.

== Acceptance testing

// aka user acceptance testing

// Performed to verify that the product is acceptable to the customer and it's fulfilling the specified requirements of the customer. This testing includes alpha and beta testing.

// Alpha testing = Alpha testing is performed at the developer's site by the customer in a closed environment. This is done after the system testing.

// Beta testing = This is done at the customer's site by the customer in an open environment. The presence of the developer, while the tests are performed, is useful but not mandatory.

== Performance testing

// Checks whether the system is performing properly, according to the user's requirements. Performance testing depends on load and stress testing processes. In load testing, the system is raised beyond is limits in order to check the performance of the system when higher-than-anticipated loads are applied. In stress testing, the system is tested beyond the normal expectations or operational capacity.

== Capacity testing (aka. load testing)

// Related: Volume testing = Testing done when huge amounts of data is processed through the application.

== Compliance testing

// Checks whether the system was developed in accordance with standards, procedures, and guidelines.

== Security testing

// Testing that confirms how well a system protects itself against unauthorised internal or external or willful damage of code. Ensures that the program is accessed by authorised personnel only.

== Error-handling testing

// Determines the ability of the system to properly process erroneous transactions.

== Usability testing

// Checks the ease-of-use, or user-friendliness, of an application.

// Related to: User interface testing = Checks how user-friendly the application is. The user should be able to use the application without any assistance by the system personnel.

== Recovery testing

// Check how fast the system is able to recover against any hardware failure, catastrophic problems or any type of system crash. ... Checking that services can be restored from backups.

== Installation testing

// Identifies the ways in which installation procedure leads to incorrect results.

// Related: compatibility testing = Determines if an application under supported configurations performs as expected, with various combinations of hardware and software packages.

// Related: configuration testing = This is done to test for compatibility issues. It determines minimal and optimal configuration of hardware and software, and determines the effect of adding or modifying resources such as memory, disk drives and CPU.

== Exploratory testing

// Similar to ad-hoc testing, and is performance to explore the software features.

== Smoke testing

// Used to check the testability of the application. This is also called build verification testing, or link testing.

